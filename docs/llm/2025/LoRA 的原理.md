---
layout: doc
title: LoRA 的原理
date: 2025-01-12
category: llm
tags: [llm, lora, parameter-efficient, fine-tuning, adaptation]
excerpt: 详细解读LoRA（Low-Rank Adaptation）的原理、公式与应用实践，是一种高效微调大模型的关键技术。
permalink: /docs/llm/2025/lora/
---

LoRA（Low-Rank Adaptation）是一种高效微调大型预训练语言模型的方法。它的核心思想是：在冻结原有大模型参数的前提下，只对特定层中权重矩阵的低秩部分进行训练微调，从而大幅降低了微调的参数量和计算资源需求。

LoRA是指Low-Rank Adaptation，一种参数高效的微调方法。具体来说，LoRA通过向模型的部分层添加可训练的低秩矩阵模块，实现模型在特定任务上的能力调整，同时保持原模型参数不变。这种技术允许在不修改原始模型的情况下，用极少的额外参数就能让模型学会新任务。LoRA的核心思想是利用矩阵的低秩分解，大幅降低微调过程中的参数量，同时保持接近全量微调的性能。例如，对于一个512*1024的权重矩阵，LoRA可以通过两个低秩矩阵的乘积来近似表示，所需更新的参数量仅为全量微调的2%左右。此外，LoRA不仅训练速度快，显存占用小，还能快速适配不同的垂直领域。在大模型微调中，LoRA成为了一种非常受欢迎的轻量级微调技术。

### 1. 原理概述

在标准的全参数微调（full fine-tuning）中，需要对全部模型参数都进行更新。但预训练大模型的参数量巨大，训练和存储成本很高。LoRA 方法通过引入秩分解，将参数变化限制在低秩空间，只需训练较少的新加参数。具体步骤如下：

1. 冻结原模型参数，禁止被优化。
2. 对如 self-attention、feed-forward 等线性层的权重矩阵 \( W_0 \in \mathbb{R}^{d \times k} \) 进行低秩分解。将要调整的权重表达为：
   \[
   W = W_0 + \Delta W
   \]
   其中
   \[
   \Delta W = BA
   \]
   其中 \( A \in \mathbb{R}^{r \times k} \)，\( B \in \mathbb{R}^{d \times r} \)，且秩 \( r \ll \min(d, k) \)。

3. 只训练 A 和 B，原有权重 W₀ 不变。
4. 推理时，用 \( W_0 + BA \) 作为层权重，无需改变模型结构。

### 2. 公式详解

假设某一层的权重为 \( W_0 \)，输入 \( x \) 时，原始输出为 \( W_0 x \)。LoRA 将其改为：
\[
y = W_0 x + BAx
\]
其中 \( BAx \) 就是“微调增量”。

### 3. 优点

- **高效**：极大减少需要训练的参数量和显存占用
- **便捷**：多数主流框架无需完全修改模型结构即可集成
- **泛化性强**：能在多任务/多领域微调中展现强大能力

### 4. 应用

LoRA 通常应用于模型如 Transformer 的 Attention 和 MLP 层，对参数最多的线性变换进行低秩插入。实践中，LoRA 已广泛用于 OpenAI GPT、LLaMA、BERT 等各种大模型的高效轻量化微调。

---

**总结**：LoRA 本质上是一种利用参数低秩分解的技巧，只需增加和训练很小一部分新参数，就能高效地让大模型具备新能力，为大模型下游任务适配和部署带来极大便利。
